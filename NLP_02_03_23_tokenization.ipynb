{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6o2tpAtbaa7sgfK6PAbLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch-kamran/ch-kamran/blob/main/NLP_02_03_23_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI26qLcbue77",
        "outputId": "c21ceac6-b223-48cd-8970-5d97ab27ee24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-02 06:06:00--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 142.251.171.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘sarcasm.json’\n",
            "\n",
            "\rsarcasm.json          0%[                    ]       0  --.-KB/s               \rsarcasm.json        100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-08-02 06:06:00 (205 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "with open('./sarcasm.json' , 'r') as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "AyDbWCVOule7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls =[]\n",
        "sentences =[]\n",
        "labels = []\n",
        "for item in data:\n",
        "  urls.append(item['article_link'])\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])"
      ],
      "metadata": {
        "id": "5fWlBg8Yuwsk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEjGZJLu3Lc",
        "outputId": "c32ea44b-be80-4373-e13e-a96fbce00baa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_size = 20000\n",
        "\n",
        "\n",
        "vocab_size = 10000\n",
        "max_length = 32\n",
        "embedding_dims = 16"
      ],
      "metadata": {
        "id": "zkCRDGXLvBx0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "trunc_type = 'post'\n",
        "oov_tok = '<oov>'\n",
        "padding_type = 'post'"
      ],
      "metadata": {
        "id": "W6L1YH9tvnOO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= Tokenizer(num_words=vocab_size ,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "tokenizer.fit_on_texts(testing_sentences)\n",
        "\n",
        "\n",
        "train_sequences=tokenizer.texts_to_sequences(training_sentences)\n",
        "test_sequences=tokenizer.texts_to_sequences(testing_sentences)\n",
        "\n",
        "train_sequences_padded=pad_sequences(train_sequences,\n",
        "                                     maxlen=max_length,\n",
        "                                     padding=padding_type,\n",
        "                                     truncating=trunc_type)\n",
        "\n",
        "test_sequences_padded=pad_sequences(test_sequences,\n",
        "                                     maxlen=max_length,\n",
        "                                     padding=padding_type,\n",
        "                                     truncating=trunc_type)\n",
        "\n",
        "training_labels = np.array(training_labels)\n",
        "test_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "ZP1DDfm1xFBr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dims, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAvgPool1D(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 30\n",
        "hist = model.fit(train_sequences_padded, training_labels,\n",
        "                 epochs=num_epochs,\n",
        "                 validation_data=(test_sequences_padded, test_labels),\n",
        "                 verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXjHxUc-yg1m",
        "outputId": "790e0428-7085-4117-a03b-adf0e8681268"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 14s - loss: 0.5604 - accuracy: 0.7011 - val_loss: 0.3954 - val_accuracy: 0.8316 - 14s/epoch - 22ms/step\n",
            "Epoch 2/30\n",
            "625/625 - 4s - loss: 0.3102 - accuracy: 0.8735 - val_loss: 0.3412 - val_accuracy: 0.8520 - 4s/epoch - 6ms/step\n",
            "Epoch 3/30\n",
            "625/625 - 2s - loss: 0.2345 - accuracy: 0.9065 - val_loss: 0.3392 - val_accuracy: 0.8559 - 2s/epoch - 3ms/step\n",
            "Epoch 4/30\n",
            "625/625 - 2s - loss: 0.1899 - accuracy: 0.9267 - val_loss: 0.3542 - val_accuracy: 0.8553 - 2s/epoch - 3ms/step\n",
            "Epoch 5/30\n",
            "625/625 - 3s - loss: 0.1592 - accuracy: 0.9412 - val_loss: 0.3802 - val_accuracy: 0.8547 - 3s/epoch - 4ms/step\n",
            "Epoch 6/30\n",
            "625/625 - 3s - loss: 0.1348 - accuracy: 0.9503 - val_loss: 0.4175 - val_accuracy: 0.8489 - 3s/epoch - 4ms/step\n",
            "Epoch 7/30\n",
            "625/625 - 3s - loss: 0.1165 - accuracy: 0.9596 - val_loss: 0.4465 - val_accuracy: 0.8486 - 3s/epoch - 5ms/step\n",
            "Epoch 8/30\n",
            "625/625 - 3s - loss: 0.1006 - accuracy: 0.9661 - val_loss: 0.4881 - val_accuracy: 0.8429 - 3s/epoch - 4ms/step\n",
            "Epoch 9/30\n",
            "625/625 - 2s - loss: 0.0873 - accuracy: 0.9714 - val_loss: 0.5297 - val_accuracy: 0.8390 - 2s/epoch - 3ms/step\n",
            "Epoch 10/30\n",
            "625/625 - 2s - loss: 0.0760 - accuracy: 0.9758 - val_loss: 0.5770 - val_accuracy: 0.8344 - 2s/epoch - 4ms/step\n",
            "Epoch 11/30\n",
            "625/625 - 3s - loss: 0.0678 - accuracy: 0.9780 - val_loss: 0.6178 - val_accuracy: 0.8348 - 3s/epoch - 4ms/step\n",
            "Epoch 12/30\n",
            "625/625 - 2s - loss: 0.0593 - accuracy: 0.9818 - val_loss: 0.6711 - val_accuracy: 0.8295 - 2s/epoch - 4ms/step\n",
            "Epoch 13/30\n",
            "625/625 - 2s - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.7256 - val_accuracy: 0.8267 - 2s/epoch - 4ms/step\n",
            "Epoch 14/30\n",
            "625/625 - 2s - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.7739 - val_accuracy: 0.8253 - 2s/epoch - 4ms/step\n",
            "Epoch 15/30\n",
            "625/625 - 2s - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.8323 - val_accuracy: 0.8229 - 2s/epoch - 4ms/step\n",
            "Epoch 16/30\n",
            "625/625 - 3s - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.8961 - val_accuracy: 0.8193 - 3s/epoch - 4ms/step\n",
            "Epoch 17/30\n",
            "625/625 - 2s - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.9462 - val_accuracy: 0.8183 - 2s/epoch - 4ms/step\n",
            "Epoch 18/30\n",
            "625/625 - 2s - loss: 0.0277 - accuracy: 0.9916 - val_loss: 1.0150 - val_accuracy: 0.8137 - 2s/epoch - 3ms/step\n",
            "Epoch 19/30\n",
            "625/625 - 2s - loss: 0.0250 - accuracy: 0.9930 - val_loss: 1.0797 - val_accuracy: 0.8119 - 2s/epoch - 4ms/step\n",
            "Epoch 20/30\n",
            "625/625 - 2s - loss: 0.0218 - accuracy: 0.9937 - val_loss: 1.1653 - val_accuracy: 0.8076 - 2s/epoch - 4ms/step\n",
            "Epoch 21/30\n",
            "625/625 - 2s - loss: 0.0207 - accuracy: 0.9937 - val_loss: 1.2216 - val_accuracy: 0.8104 - 2s/epoch - 3ms/step\n",
            "Epoch 22/30\n",
            "625/625 - 3s - loss: 0.0186 - accuracy: 0.9947 - val_loss: 1.2707 - val_accuracy: 0.8088 - 3s/epoch - 4ms/step\n",
            "Epoch 23/30\n",
            "625/625 - 2s - loss: 0.0157 - accuracy: 0.9953 - val_loss: 1.3607 - val_accuracy: 0.8050 - 2s/epoch - 4ms/step\n",
            "Epoch 24/30\n",
            "625/625 - 2s - loss: 0.0158 - accuracy: 0.9955 - val_loss: 1.3913 - val_accuracy: 0.8062 - 2s/epoch - 4ms/step\n",
            "Epoch 25/30\n",
            "625/625 - 2s - loss: 0.0135 - accuracy: 0.9965 - val_loss: 1.4520 - val_accuracy: 0.8065 - 2s/epoch - 4ms/step\n",
            "Epoch 26/30\n",
            "625/625 - 2s - loss: 0.0117 - accuracy: 0.9969 - val_loss: 1.5283 - val_accuracy: 0.8046 - 2s/epoch - 4ms/step\n",
            "Epoch 27/30\n",
            "625/625 - 3s - loss: 0.0098 - accuracy: 0.9973 - val_loss: 1.5956 - val_accuracy: 0.8031 - 3s/epoch - 5ms/step\n",
            "Epoch 28/30\n",
            "625/625 - 2s - loss: 0.0091 - accuracy: 0.9977 - val_loss: 1.6687 - val_accuracy: 0.8044 - 2s/epoch - 3ms/step\n",
            "Epoch 29/30\n",
            "625/625 - 2s - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.7522 - val_accuracy: 0.8013 - 2s/epoch - 3ms/step\n",
            "Epoch 30/30\n",
            "625/625 - 2s - loss: 0.0083 - accuracy: 0.9976 - val_loss: 1.8067 - val_accuracy: 0.8041 - 2s/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsFwa9Tp07f5",
        "outputId": "ef6d23f2-75b7-434e-96e9-382ec32ce25a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 32, 16)            160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,577\n",
            "Trainable params: 160,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}